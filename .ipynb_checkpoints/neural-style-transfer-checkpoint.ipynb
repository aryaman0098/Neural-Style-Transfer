{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg19.VGG19(include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_LAYER = [\"block5_conv2\"]\n",
    "STYLE_LAYER = [\"block4_conv1\",\"block4_conv2\",\"block4_conv3\",\"block4_conv4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel():\n",
    "    baseModel=vgg19.VGG19(include_top=False,weights=\"imagenet\")\n",
    "    baseModel.trainable = False\n",
    "    contentLayers = CONTENT_LAYER\n",
    "    styleLayers = STYLE_LAYER\n",
    "    outputLayers = [baseModel.get_layer(layer).output for layer in (contentLayers + styleLayers)]\n",
    "    return tf.keras.models.Model(baseModel.input,outputLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess(processedImg):\n",
    "    unprocessedImg = processedImg - VGG_BIASES\n",
    "    unprocessedImg = tf.unstack(unprocessedImg,axis=-1)\n",
    "    unprocessedImg = tf.stack([unprocessedImg[2],unprocessedImg[1],unprocessedImg[0]],axis=-1)\n",
    "    return unprocessedImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContentLoss(newImageContent, baseImageContent):\n",
    "    return np.mean(np.square(newImageContent - baseImageContent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGramMatrix(output):\n",
    "    firstStyleLayer = output\n",
    "    A = tf.reshape(firstStyleLayer,(-1,firstStyleLayer.shape[-1])) \n",
    "    n = A.shape[0]\n",
    "    gramMatrix = tf.matmul(A,A,transpose_a=True)\n",
    "    n=gramMatrix.shape[0]\n",
    "    return gramMatrix/tf.cast(n,\"float32\"), n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStyleLoss(newImageStyle, baseStyle):\n",
    "    newStyleGram, gramNumHt1 = getGramMatrix(newImageStyle)\n",
    "    baseStyleGram, gramNumHt2 = getGramMatrix(baseStyle)\n",
    "    assert gramNumHt1 == gramNumHt2\n",
    "    gramNumFeatures = newStyleGram.shape[0]\n",
    "    loss = tf.reduce_sum(tf.square((baseStyleGram - newStyleGram)/2)/(4*(gramNumHt1**2)*(gramNumHt2**2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalLoss(newImageOutput, baseContentImageOuput, baseStyleImageOuput, alpha = 0.0001, beta = .9999):\n",
    "    newImageStyles = newImageOutput[len(CONTENT_LAYER):]\n",
    "    baseImageStyles = baseStyleImageOuput[len(CONTENT_LAYER):]\n",
    "    styleLoss = 0\n",
    "    n = len(newImageStyles)\n",
    "    for i in range(n):\n",
    "        styleLoss += getStyleLoss(newImageStyles[i], baseImageStyles[i])\n",
    "        \n",
    "    newImageContents = newImageOutput[:len(CONTENT_LAYER)]\n",
    "    baseImageContents = baseContentImageOuput[:len(CONTENT_LAYER)]\n",
    "    contentLoss = 0\n",
    "    n = len(newImageContents)\n",
    "    for i in range(n):\n",
    "        contentLoss += getContentLoss(newImageContents[i], baseImageContents[i]) / n\n",
    "    \n",
    "    return alpha * contentLoss + beta * styleLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralStyleTransfer(processedContentVar, baseContentOutput, baseStyleOutputs, VGG_BIASES, numIterations):\n",
    "    images = []\n",
    "    losses =[]\n",
    "    i=0\n",
    "    bestLoss =2000000000\n",
    "    minVals = VGG_BIASES\n",
    "    maxVals = 255 + VGG_BIASES\n",
    "    for i in range(numIterations):   \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(processedContentVar)\n",
    "            contentVarOutputs = baseModel(processedContentVar)\n",
    "            loss = getTotalLoss(contentVarOutputs, baseContentOutput, baseStyleOutputs)\n",
    "            grad = tape.gradient(loss, processedContentVar)\n",
    "            losses.append(loss)\n",
    "            optimizer.apply_gradients(zip([grad],[processedContentVar]))\n",
    "            clipped = tf.clip_by_value(processedContentVar, minVals, maxVals)\n",
    "            processedContentVar.assign(clipped)\n",
    "            if i % 5 == 0:\n",
    "                images.append(deprocess(processedContentVar))\n",
    "            if loss < bestLoss:\n",
    "                bestImage = processedContentVar\n",
    "                bestLoss = loss\n",
    "            display(i)\n",
    "            display(loss)\n",
    "            clear_output(wait=True)\n",
    "    return images, losses, bestImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImagePath = \"../input/neural-syle-transfer/mlCourseProject/input/4-content.jpg\"\n",
    "styleImagePath = \"../input/neural-syle-transfer/7-style.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImage = np.asarray(tf.keras.preprocessing.image.load_img(contentImagePath, target_size = (512, 512)))\n",
    "styleImage = np.asarray(tf.keras.preprocessing.image.load_img(styleImagePath, target_size = (512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "ax1.imshow(contentImage)\n",
    "ax1.set_title(\"Content Image\")\n",
    "ax2.imshow(styleImage)\n",
    "ax2.set_title(\"Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImage.shape, styleImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentImage = vgg19.preprocess_input(np.expand_dims(contentImage, axis = 0))\n",
    "processedStyleImage = vgg19.preprocess_input(np.expand_dims(styleImage, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentImage.shape, processedStyleImage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_BIASES = vgg19.preprocess_input((np.zeros((3))).astype(\"float32\"))\n",
    "print(VGG_BIASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "ax1.imshow(processedContentImage[0])\n",
    "ax1.set_title(\"Processed Content Image\")\n",
    "ax2.imshow(processedStyleImage[0])\n",
    "ax2.set_title(\"Processed Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "ax1.imshow(deprocess(processedContentImage)[0]/255)\n",
    "ax1.set_title(\"Deprocessed Content Image\")\n",
    "ax2.imshow(deprocess(processedStyleImage)[0]/255)\n",
    "ax2.set_title(\"Deprocessed Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = makeModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImgOutputs = baseModel(processedContentImage)\n",
    "styleImgOutputs = baseModel(processedStyleImage)\n",
    "len(contentImgOutputs), len(styleImgOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contentImgOutputs[0].shape, styleImgOutputs[0].shape)\n",
    "print(contentImgOutputs[1].shape, styleImgOutputs[1].shape)\n",
    "print(contentImgOutputs[2].shape, styleImgOutputs[2].shape)\n",
    "print(contentImgOutputs[3].shape, styleImgOutputs[3].shape)\n",
    "print(contentImgOutputs[4].shape, styleImgOutputs[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getContentLoss(contentImgOutputs[0], contentImgOutputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramMatrices = []\n",
    "for i in range(1, 5):\n",
    "    gramMatrices.append(getGramMatrix(styleImgOutputs[i]))\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows = 1, ncols = 4)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "ax1.imshow(gramMatrices[0][0].numpy())\n",
    "ax2.imshow(gramMatrices[1][0].numpy())\n",
    "ax3.imshow(gramMatrices[2][0].numpy())\n",
    "ax4.imshow(gramMatrices[3][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTotalLoss(contentImgOutputs, styleImgOutputs, contentImgOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(processedContentVar[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(5,beta_1=.99,epsilon=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images1, losses1, bestImage1 = neuralStyleTransfer(processedContentVar, contentImgOutputs, styleImgOutputs, VGG_BIASES, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images2, losses2, bestImage2 = neuralStyleTransfer(processedContentVar, contentImgOutputs, styleImgOutputs, VGG_BIASES, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images3, losses3, bestImage3 = neuralStyleTransfer(processedContentVar, contentImgOutputs, styleImgOutputs, VGG_BIASES, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images4, losses4, bestImage4 = neuralStyleTransfer(processedContentVar, contentImgOutputs, styleImgOutputs, VGG_BIASES, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprocessedBestImage1 = deprocess(bestImage1)\n",
    "deprocessedBestImage2 = deprocess(bestImage2)\n",
    "deprocessedBestImage3 = deprocess(bestImage3)\n",
    "deprocessedBestImage4 = deprocess(bestImage4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows = 1, ncols = 4)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "ax1.imshow(deprocessedBestImage1[0]/255)\n",
    "ax1.set_title(\"Iteration : 50\")\n",
    "ax2.imshow(deprocessedBestImage2[0]/255)\n",
    "ax2.set_title(\"Iteration : 100\")\n",
    "ax3.imshow(deprocessedBestImage3[0]/255)\n",
    "ax3.set_title(\"Iteration : 150\")\n",
    "ax4.imshow(deprocessedBestImage4[0]/255)\n",
    "ax4.set_title(\"Iteration : 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalLossForMultipleImages(newImageOutput, baseContentImageOuput, baseStyleImageOuput1, baseStyleImageOuput2, beta1, beta2, alpha = 0.0001):\n",
    "    newImageStyles = newImageOutput[len(CONTENT_LAYER):]\n",
    "    baseImageStyles1 = baseStyleImageOuput1[len(CONTENT_LAYER):]\n",
    "    baseImageStyles2 = baseStyleImageOuput2[len(CONTENT_LAYER):]\n",
    "    styleLoss1 = 0\n",
    "    n = len(newImageStyles)\n",
    "    for i in range(n):\n",
    "        styleLoss1 += getStyleLoss(newImageStyles[i], baseImageStyles1[i])\n",
    "    styleLoss2 = 0\n",
    "    for i in range(n):\n",
    "        styleLoss2 += getStyleLoss(newImageStyles[i], baseImageStyles2[i])\n",
    "    \n",
    "    newImageContents = newImageOutput[:len(CONTENT_LAYER)]\n",
    "    baseImageContents = baseContentImageOuput[:len(CONTENT_LAYER)]\n",
    "    contentLoss = 0\n",
    "    n = len(newImageContents)\n",
    "    for i in range(n):\n",
    "        contentLoss += getContentLoss(newImageContents[i], baseImageContents[i]) / n\n",
    "    \n",
    "    return alpha * contentLoss + beta1 * styleLoss1 + beta2 * styleLoss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralStyleTransferForMultipleImages(processedContentVar, baseContentOutput, baseStyleOutputs1, baseStyleOutputs2, VGG_BIASES, numIterations, beta1, beta2):\n",
    "    images = []\n",
    "    losses =[]\n",
    "    i=0\n",
    "    bestLoss =2000000000\n",
    "    minVals = VGG_BIASES\n",
    "    maxVals = 255 + VGG_BIASES\n",
    "    for i in range(numIterations):   \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(processedContentVar)\n",
    "            contentVarOutputs = baseModel(processedContentVar)\n",
    "            loss = getTotalLossForMultipleImages(contentVarOutputs, baseContentOutput, baseStyleOutputs1, baseStyleOutputs2, beta1, beta2)\n",
    "            grad = tape.gradient(loss, processedContentVar)\n",
    "            losses.append(loss)\n",
    "            optimizer.apply_gradients(zip([grad],[processedContentVar]))\n",
    "            clipped = tf.clip_by_value(processedContentVar, minVals, maxVals)\n",
    "            processedContentVar.assign(clipped)\n",
    "            if i % 2 == 0:\n",
    "                images.append(deprocess(processedContentVar))\n",
    "            if loss < bestLoss:\n",
    "                bestImage = processedContentVar\n",
    "                bestLoss = loss\n",
    "            display(i)\n",
    "            display(loss)\n",
    "            clear_output(wait=True)\n",
    "    return images, losses, bestImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImagePath = \"../input/neural-syle-transfer/mlCourseProject/input/4-content.jpg\"\n",
    "styleImagePath1 = \"../input/neural-syle-transfer/7-style.png\"\n",
    "styleImagePath2 = \"../input/neural-syle-transfer/mlCourseProject/input/4-style.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImage = np.asarray(tf.keras.preprocessing.image.load_img(contentImagePath, target_size = (512, 512)))\n",
    "styleImage1 = np.asarray(tf.keras.preprocessing.image.load_img(styleImagePath1, target_size = (512, 512)))\n",
    "styleImage2 = np.asarray(tf.keras.preprocessing.image.load_img(styleImagePath2, target_size = (512, 512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "ax1.imshow(contentImage)\n",
    "ax1.set_title(\"Content Image\")\n",
    "ax2.imshow(styleImage1)\n",
    "ax2.set_title(\"Style Image1\")\n",
    "ax3.imshow(styleImage2)\n",
    "ax3.set_title(\"Style Image2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImage.shape, styleImage1.shape, styleImage2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentImage = vgg19.preprocess_input(np.expand_dims(contentImage, axis = 0))\n",
    "processedStyleImage1 = vgg19.preprocess_input(np.expand_dims(styleImage1, axis = 0))\n",
    "processedStyleImage2 = vgg19.preprocess_input(np.expand_dims(styleImage2, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "ax1.imshow(processedContentImage[0])\n",
    "ax1.set_title(\"Processed Content Image\")\n",
    "ax2.imshow(processedStyleImage1[0])\n",
    "ax2.set_title(\"Processed Style Image\")\n",
    "ax3.imshow(processedStyleImage2[0])\n",
    "ax3.set_title(\"Processed Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3)\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(7)\n",
    "ax1.imshow(deprocess(processedContentImage)[0]/255)\n",
    "ax1.set_title(\"Deprocessed Content Image\")\n",
    "ax2.imshow(deprocess(processedStyleImage1)[0]/255)\n",
    "ax2.set_title(\"Deprocessed Style Image\")\n",
    "ax3.imshow(deprocess(processedStyleImage2)[0]/255)\n",
    "ax3.set_title(\"Deprocessed Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImgOutputs = baseModel(processedContentImage)\n",
    "styleImgOutputs1 = baseModel(processedStyleImage1)\n",
    "styleImgOutputs2 = baseModel(processedStyleImage2)\n",
    "len(contentImgOutputs), len(styleImgOutputs1), len(styleImgOutputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images1, losses1, Image1 = neuralStyleTransferForMultipleImages(processedContentVar, contentImgOutputs, styleImgOutputs1, styleImgOutputs2, VGG_BIASES, 100, 1.0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images2, losses2, Image2 = neuralStyleTransferForMultipleImages(processedContentVar, contentImgOutputs, styleImgOutputs1, styleImgOutputs2, VGG_BIASES, 100, 0.75, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images3, losses3, Image3 = neuralStyleTransferForMultipleImages(processedContentVar, contentImgOutputs, styleImgOutputs1, styleImgOutputs2, VGG_BIASES, 100, 0.50, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images4, losses4, Image4 = neuralStyleTransferForMultipleImages(processedContentVar, contentImgOutputs, styleImgOutputs1, styleImgOutputs2, VGG_BIASES, 100, 0.25, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentVar = tf.Variable(processedContentImage + tf.random.normal(processedContentImage.shape))\n",
    "images5, losses5, Image5 = neuralStyleTransferForMultipleImages(processedContentVar, contentImgOutputs, styleImgOutputs1, styleImgOutputs2, VGG_BIASES, 100, 0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprocessedBestImage1 = deprocess(Image1)\n",
    "deprocessedBestImage2 = deprocess(Image2)\n",
    "deprocessedBestImage3 = deprocess(Image3)\n",
    "deprocessedBestImage4 = deprocess(Image4)\n",
    "deprocessedBestImage5 = deprocess(Image5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows = 1, ncols = 5)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(20)\n",
    "ax1.imshow(deprocessedBestImage1[0]/255)\n",
    "ax1.set_title(\"Variation1\")\n",
    "ax2.imshow(deprocessedBestImage2[0]/255)\n",
    "ax2.set_title(\"Variation2\")\n",
    "ax3.imshow(deprocessedBestImage3[0]/255)\n",
    "ax3.set_title(\"Variation3\")\n",
    "ax4.imshow(deprocessedBestImage4[0]/255)\n",
    "ax4.set_title(\"Variation4\")\n",
    "ax5.imshow(deprocessedBestImage5[0]/255)\n",
    "ax5.set_title(\"Variation5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagePath = \"../input/neural-syle-transfer/mlCourseProject/input/4-content.jpg\"\n",
    "styleImage1Path = \"../input/neural-syle-transfer/7-style.png\"\n",
    "styleImage2Path = \"../input/neural-syle-transfer/mlCourseProject/input/4-style.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = np.asarray(tf.keras.preprocessing.image.load_img(contentImagePath, target_size = (512, 512)))\n",
    "styleImage1 = np.asarray(tf.keras.preprocessing.image.load_img(styleImagePath1, target_size = (256, 256)))\n",
    "styleImage2 = np.asarray(tf.keras.preprocessing.image.load_img(styleImagePath2, target_size = (256, 256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "ax1.imshow(Image)\n",
    "ax1.set_title(\"Content Image\")\n",
    "ax2.imshow(styleImage1)\n",
    "ax2.set_title(\"Style Image\")\n",
    "ax3.imshow(styleImage2)\n",
    "ax3.set_title(\"Style Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImage1 = np.zeros((256, 256, 3))\n",
    "for i in range (0, 256):\n",
    "    for j in range (0, 256):\n",
    "        for k in range (0, 3):\n",
    "            contentImage1[i][j][k] = Image[i][j][k]\n",
    "contentImage2 = np.zeros((256, 256, 3))\n",
    "for i in range (0, 256):\n",
    "    for j in range (256, 512):\n",
    "        for k in range (0, 3):\n",
    "            contentImage2[i][j-256][k] = Image[i][j][k]\n",
    "contentImage3 = np.zeros((256, 256, 3))\n",
    "for i in range (256, 512):\n",
    "    for j in range (0, 256):\n",
    "        for k in range (0, 3):\n",
    "            contentImage3[i-256][j][k] = Image[i][j][k]\n",
    "contentImage4 = np.zeros((256, 256, 3))\n",
    "for i in range (256, 512):\n",
    "    for j in range (256, 512):\n",
    "        for k in range (0, 3):\n",
    "            contentImage4[i-256][j-256][k] = Image[i][j][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows = 1, ncols = 4)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "ax1.imshow(contentImage1/255)\n",
    "ax2.imshow(contentImage2/255)\n",
    "ax3.imshow(contentImage3/255)\n",
    "ax4.imshow(contentImage4/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContentImage1 = vgg19.preprocess_input(np.expand_dims(contentImage1, axis = 0))\n",
    "processedContentImage2 = vgg19.preprocess_input(np.expand_dims(contentImage2, axis = 0))\n",
    "processedContentImage3 = vgg19.preprocess_input(np.expand_dims(contentImage3, axis = 0))\n",
    "processedContentImage4 = vgg19.preprocess_input(np.expand_dims(contentImage4, axis = 0))\n",
    "processedStyleImage1 = vgg19.preprocess_input(np.expand_dims(styleImage1, axis = 0))\n",
    "processedStyleImage2 = vgg19.preprocess_input(np.expand_dims(styleImage2, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentImg1Outputs = baseModel(processedContentImage1)\n",
    "contentImg2Outputs = baseModel(processedContentImage2)\n",
    "contentImg3Outputs = baseModel(processedContentImage3)\n",
    "contentImg4Outputs = baseModel(processedContentImage4)\n",
    "styleImgOutputs1 = baseModel(processedStyleImage1)\n",
    "styleImgOutputs2 = baseModel(processedStyleImage2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTotalLoss(contentImg1Outputs, contentImg2Outputs, styleImgOutputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContent1Var = tf.Variable(processedContentImage1 + tf.random.normal(processedContentImage1.shape))\n",
    "images1, losses1, bestImage1 = neuralStyleTransfer(processedContent1Var, contentImg1Outputs, styleImgOutputs1, VGG_BIASES, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContent2Var = tf.Variable(processedContentImage2 + tf.random.normal(processedContentImage2.shape))\n",
    "images2, losses2, bestImage2 = neuralStyleTransfer(processedContent2Var, contentImg2Outputs, styleImgOutputs2, VGG_BIASES, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContent3Var = tf.Variable(processedContentImage3 + tf.random.normal(processedContentImage3.shape))\n",
    "images3, losses3, bestImage3 = neuralStyleTransfer(processedContent3Var, contentImg3Outputs, styleImgOutputs2, VGG_BIASES, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedContent4Var = tf.Variable(processedContentImage4 + tf.random.normal(processedContentImage4.shape))\n",
    "images1, losses1, bestImage4 = neuralStyleTransfer(processedContent4Var, contentImg4Outputs, styleImgOutputs1, VGG_BIASES, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprocessedBestImage1 = deprocess(bestImage1)\n",
    "deprocessedBestImage2 = deprocess(bestImage2)\n",
    "deprocessedBestImage3 = deprocess(bestImage3)\n",
    "deprocessedBestImage4 = deprocess(bestImage4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quater1 = np.asarray(deprocessedBestImage1[0])\n",
    "quater2 = np.asarray(deprocessedBestImage2[0])\n",
    "quater3 = np.asarray(deprocessedBestImage3[0])\n",
    "quater4 = np.asarray(deprocessedBestImage4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeImage = np.zeros((512, 512, 3))\n",
    "for i in range (0, 256):\n",
    "    for j in range (0, 256):\n",
    "        for k in range (0, 3):\n",
    "            completeImage[i][j][k] = quater1[i][j][k]\n",
    "for i in range (0, 256):\n",
    "    for j in range (256, 512):\n",
    "        for k in range (0, 3):\n",
    "            completeImage[i][j][k] = quater2[i][j-256][k]\n",
    "for i in range (256, 512):\n",
    "    for j in range (0, 256):\n",
    "        for k in range (0, 3):\n",
    "            completeImage[i][j][k] = quater3[i-256][j][k]\n",
    "for i in range (256, 512):\n",
    "    for j in range (256, 512):\n",
    "        for k in range (0, 3):\n",
    "            completeImage[i][j][k] = quater4[i-256][j-256][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(completeImage/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
